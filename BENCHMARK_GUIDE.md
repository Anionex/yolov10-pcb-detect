# PCBæ£€æµ‹Benchmarkä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•
- [ç®€ä»‹](#ç®€ä»‹)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ•°æ®é›†å‡†å¤‡](#æ•°æ®é›†å‡†å¤‡)
- [è¿è¡ŒBenchmark](#è¿è¡Œbenchmark)
- [é…ç½®ä¼˜åŒ–å®éªŒ](#é…ç½®ä¼˜åŒ–å®éªŒ)
- [ç»“æœåˆ†æ](#ç»“æœåˆ†æ)
- [FAQ](#faq)

---

## ç®€ä»‹

è¿™ä¸ªBenchmarkæ¨¡å—ç”¨äºç³»ç»ŸåŒ–è¯„ä¼°PCBç‘•ç–µæ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ï¼Œæ”¯æŒï¼š

âœ… **æ ‡å‡†è¯„ä¼°æŒ‡æ ‡**: mAP, Precision, Recall, F1
âœ… **é€Ÿåº¦åˆ†æ**: FPS, æ¨ç†æ—¶é—´ç»Ÿè®¡
âœ… **ç±»åˆ«çº§åˆ«è¯„ä¼°**: æ¯ä¸ªç‘•ç–µç±»å‹çš„è¯¦ç»†æŒ‡æ ‡
âœ… **å¤šé…ç½®å¯¹æ¯”**: æ‰¹é‡æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆ
âœ… **ç»“æœå¯è§†åŒ–**: JSONå’ŒCSVæ ¼å¼è¾“å‡º

---

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å¦‚æœè¿˜æ²¡å®‰è£…ï¼Œæ·»åŠ ä»¥ä¸‹ä¾èµ–
pip install pyyaml pandas tqdm
```

### 2. å‡†å¤‡æµ‹è¯•æ•°æ®

å°†æµ‹è¯•é›†ç»„ç»‡ä¸ºYOLOæ ¼å¼ï¼š

```
datasets/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ image1.jpg
    â”‚   â”œâ”€â”€ image2.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ labels/
        â”œâ”€â”€ image1.txt
        â”œâ”€â”€ image2.txt
        â””â”€â”€ ...
```

æˆ–è€…ç›´æ¥å°†å›¾ç‰‡å’Œæ ‡æ³¨æ”¾åœ¨åŒä¸€ç›®å½•ï¼š

```
datasets/test/
â”œâ”€â”€ image1.jpg
â”œâ”€â”€ image1.txt
â”œâ”€â”€ image2.jpg
â”œâ”€â”€ image2.txt
â””â”€â”€ ...
```

### 3. å¿«é€Ÿæµ‹è¯•

```bash
# æ–¹å¼1: ç›´æ¥è¿è¡Œï¼ˆä¼šæ˜¾ç¤ºäº¤äº’èœå•ï¼‰
python run_benchmark.py

# æ–¹å¼2: å¿«é€Ÿæµ‹è¯•å•å¼ å›¾ç‰‡
python run_benchmark.py --mode quick --image data/test_pcb.jpg

# æ–¹å¼3: è¿è¡Œå®Œæ•´benchmark
python benchmark.py --dataset_path datasets/test --model_path weights/best.pt
```

---

## æ•°æ®é›†å‡†å¤‡

### YOLOæ ‡æ³¨æ ¼å¼

æ¯ä¸ª`.txt`æ–‡ä»¶å¯¹åº”ä¸€å¼ å›¾ç‰‡ï¼Œæ ¼å¼ä¸ºï¼š

```
<class_id> <center_x> <center_y> <width> <height>
```

å…¶ä¸­åæ ‡éƒ½æ˜¯å½’ä¸€åŒ–çš„(0-1)ã€‚

**ä¾‹å­**:
```
0 0.5 0.5 0.2 0.3
3 0.7 0.3 0.15 0.25
```

### ç±»åˆ«æ˜ å°„

åœ¨`config.py`ä¸­å®šä¹‰ï¼š

```python
id2cls_name_custom = [
    "Mouse_bite",      # 0
    "Spur",            # 1
    "Missing_hole",    # 2
    "Short",           # 3
    "Open_circuit",    # 4
    "Spurious_copper"  # 5
]
```

### å·²æœ‰æ•°æ®é›†è½¬æ¢

é¡¹ç›®ä¸­æä¾›äº†è½¬æ¢å·¥å…·ï¼š

```bash
# PKUæ•°æ®é›†è½¬æ¢
python utils/pku_dataset_convert_to_yolo.py

# DeepPCBæ•°æ®é›†è½¬æ¢
python utils/deep_pcb_dataset_convert_to_yolo.py
```

---

## è¿è¡ŒBenchmark

### æ–¹æ³•1: ä½¿ç”¨å‘½ä»¤è¡Œ

```bash
# åŸºç¡€ç”¨æ³•
python benchmark.py \
    --dataset_path datasets/test \
    --model_path weights/best.pt \
    --conf_threshold 0.4 \
    --nms_threshold 0.1

# è‡ªå®šä¹‰ä¿å­˜ç›®å½•
python benchmark.py \
    --dataset_path datasets/test \
    --model_path weights/best.pt \
    --save_dir my_benchmark_results
```

### æ–¹æ³•2: ä½¿ç”¨é…ç½®æ–‡ä»¶

1. **ç¼–è¾‘é…ç½®** (`benchmark_config.yaml`):

```yaml
base:
  model_path: "weights/best.pt"
  dataset_path: "datasets/test"  # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„
  conf_threshold: 0.4
  nms_threshold: 0.1
```

2. **è¿è¡Œ**:

```bash
python run_benchmark.py --mode single
```

### æ–¹æ³•3: äº¤äº’å¼èœå•

```bash
python run_benchmark.py

# ç„¶åæ ¹æ®æç¤ºé€‰æ‹©ï¼š
# 1. å¿«é€Ÿæµ‹è¯•
# 2. å•æ¬¡Benchmark
# 3. æ‰¹é‡å®éªŒ
# 4. å¯¹æ¯”å·²æœ‰ç»“æœ
```

---

## é…ç½®ä¼˜åŒ–å®éªŒ

### æ‰¹é‡æµ‹è¯•ä¸åŒé…ç½®

`benchmark_config.yaml`ä¸­é¢„å®šä¹‰äº†å¤šç§å®éªŒé…ç½®ï¼š

```yaml
experiments:
  baseline:
    name: "Baseline (current)"
    conf_threshold: 0.4
    nms_threshold: 0.1
    
  high_confidence:
    name: "High Confidence"
    conf_threshold: 0.5
    
  more_overlap:
    name: "More Overlap"
    step_size: 160  # æ›´å¤šçª—å£é‡å 
```

**è¿è¡Œæ‰¹é‡å®éªŒ**:

```bash
python run_benchmark.py --mode batch
```

è¿™ä¼šä¾æ¬¡è¿è¡Œæ‰€æœ‰é…ç½®ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šã€‚

### è‡ªå®šä¹‰å®éªŒ

åœ¨`benchmark_config.yaml`ä¸­æ·»åŠ ï¼š

```yaml
experiments:
  my_experiment:
    name: "My Custom Config"
    conf_threshold: 0.45
    nms_threshold: 0.15
    window_size: 672
    step_size: 336
```

---

## ç»“æœåˆ†æ

### è¾“å‡ºæ–‡ä»¶

Benchmarkè¿è¡Œåä¼šç”Ÿæˆï¼š

```
benchmark_results/
â”œâ”€â”€ benchmark_20241103_143025.json  # è¯¦ç»†ç»“æœ
â”œâ”€â”€ benchmark_20241103_143025.csv   # è¡¨æ ¼æ ¼å¼
â””â”€â”€ comparison_latest.json          # å¯¹æ¯”ç»“æœï¼ˆå¦‚æœè¿è¡Œäº†å¤šä¸ªï¼‰
```

### JSONç»“æœç»“æ„

```json
{
  "timestamp": "2024-11-03 14:30:25",
  "model_path": "weights/best.pt",
  "config": {
    "conf_threshold": 0.4,
    "nms_threshold": 0.1,
    "window_size": 608,
    "step_size": 320
  },
  "metrics": {
    "overall": {
      "precision": 0.8523,
      "recall": 0.7891,
      "f1": 0.8193,
      "mAP": 0.8012
    },
    "per_class": {
      "Short": {
        "precision": 0.9012,
        "recall": 0.8523,
        "f1": 0.8760,
        "ap": 0.8654
      },
      ...
    }
  },
  "speed": {
    "mean_time": 2.345,
    "fps": 0.426,
    "total_images": 50
  }
}
```

### å…³é”®æŒ‡æ ‡è§£è¯»

| æŒ‡æ ‡ | å«ä¹‰ | å»ºè®® |
|------|------|------|
| **mAP@0.5** | å¹³å‡ç²¾åº¦ (IoUâ‰¥0.5) | å·¥ä¸šåº”ç”¨æœ€é‡è¦æŒ‡æ ‡ï¼Œå»ºè®®â‰¥0.8 |
| **Precision** | æŸ¥å‡†ç‡ | å‡å°‘è¯¯æŠ¥ï¼Œå»ºè®®â‰¥0.85 |
| **Recall** | å¬å›ç‡ | å‡å°‘æ¼æ£€ï¼Œå»ºè®®â‰¥0.80 |
| **F1 Score** | ç»¼åˆæŒ‡æ ‡ | å¹³è¡¡ç²¾ç¡®å’Œå¬å› |
| **FPS** | æ¯ç§’å¸§æ•° | å®æ—¶æ€§è¦æ±‚ |

### å¯¹æ¯”å¤šä¸ªé…ç½®

```bash
# æ‰‹åŠ¨å¯¹æ¯”
python benchmark.py --compare \
    benchmark_results/benchmark_20241103_120000.json \
    benchmark_results/benchmark_20241103_130000.json \
    benchmark_results/benchmark_20241103_140000.json
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
Model                          mAP        Precision    Recall       F1         FPS
--------------------------------------------------------------------------------
baseline                       0.8012     0.8523       0.7891       0.8193     0.43
high_confidence                0.7856     0.8945       0.7234       0.7998     0.43
more_overlap                   0.8234     0.8612       0.8123       0.8360     0.21
```

---

## ä¼˜åŒ–æŒ‡å—

### æ ¹æ®ç»“æœè°ƒä¼˜

#### æƒ…å†µ1: Precisioné«˜ï¼ŒRecallä½

**é—®é¢˜**: æ¼æ£€å¤ªå¤š
**è§£å†³**:
- é™ä½`conf_threshold` (0.4 â†’ 0.3)
- å¢åŠ çª—å£é‡å  (`step_size` 320 â†’ 160)
- å°è¯•å¤šå°ºåº¦æµ‹è¯•

#### æƒ…å†µ2: Recallé«˜ï¼ŒPrecisionä½

**é—®é¢˜**: è¯¯æ£€å¤ªå¤š
**è§£å†³**:
- æé«˜`conf_threshold` (0.4 â†’ 0.5)
- é™ä½`nms_threshold` (0.1 â†’ 0.05)
- æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡

#### æƒ…å†µ3: é€Ÿåº¦å¤ªæ…¢

**ä¼˜åŒ–**:
- å¢å¤§`step_size` (320 â†’ 480)
- å‡å°`window_size` (608 â†’ 544)
- è€ƒè™‘æ¨¡å‹å‹ç¼©/é‡åŒ–

#### æƒ…å†µ4: æŸäº›ç±»åˆ«APå¾ˆä½

**åˆ†æ**:
- æŸ¥çœ‹per_classç»“æœ
- å¯èƒ½éœ€è¦é’ˆå¯¹è¯¥ç±»åˆ«æ”¶é›†æ›´å¤šè®­ç»ƒæ•°æ®
- è€ƒè™‘ç±»åˆ«å¹³è¡¡ç­–ç•¥

---

## å®éªŒå»ºè®®

### æ¨èçš„å®éªŒæµç¨‹

1. **å»ºç«‹åŸºçº¿** (Baseline)
   ```bash
   python benchmark.py --dataset_path datasets/test
   ```

2. **è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼** (0.3, 0.4, 0.5, 0.6)
   ```bash
   # æ‰¹é‡æµ‹è¯•
   python run_benchmark.py --mode batch
   ```

3. **ä¼˜åŒ–æ»‘åŠ¨çª—å£** (step_size: 160, 240, 320, 480)
   - è§‚å¯ŸmAP vs Speedæƒè¡¡

4. **æµ‹è¯•TTAå¢å¼º** (å¦‚æœå®ç°)
   - è¯„ä¼°ç²¾åº¦æå‡æ˜¯å¦å€¼å¾—æ—¶é—´å¼€é”€

5. **å°è¯•WBFæ›¿ä»£NMS**
   - ä¿®æ”¹`customize_service.py`å®ç°

6. **Multi-scaleæµ‹è¯•**
   - ä¸åŒwindow_sizeç»„åˆ

### è®°å½•å®éªŒ

å»ºè®®ä½¿ç”¨è¡¨æ ¼è®°å½•ï¼š

| å®éªŒID | é…ç½® | mAP | Precision | Recall | FPS | å¤‡æ³¨ |
|--------|------|-----|-----------|--------|-----|------|
| exp001 | baseline | 0.801 | 0.852 | 0.789 | 0.43 | å½“å‰é…ç½® |
| exp002 | conf=0.5 | 0.785 | 0.894 | 0.723 | 0.43 | è¯¯æ£€å°‘ä½†æ¼æ£€å¤š |
| exp003 | step=160 | 0.823 | 0.861 | 0.812 | 0.21 | æœ€ä½³ç²¾åº¦ï¼Œæ…¢2å€ |

---

## FAQ

### Q1: è¿è¡ŒæŠ¥é”™ "No valid test data found"

**A**: æ£€æŸ¥ï¼š
- `dataset_path`æ˜¯å¦æ­£ç¡®
- å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- æ–‡ä»¶æ‰©å±•åæ˜¯å¦æ”¯æŒ (.jpg, .png, .bmp)

### Q2: mAPè®¡ç®—ç»“æœä¸º0

**A**: å¯èƒ½åŸå› ï¼š
- IoUé˜ˆå€¼å¤ªé«˜ï¼Œæ²¡æœ‰åŒ¹é…çš„æ£€æµ‹æ¡†
- ç±»åˆ«IDä¸åŒ¹é…ï¼ˆæ£€æŸ¥`config.py`ï¼‰
- æ¨¡å‹å®Œå…¨æ²¡æ£€æµ‹åˆ°ç›®æ ‡

### Q3: å¦‚ä½•åªæµ‹è¯•ç‰¹å®šç±»åˆ«ï¼Ÿ

**A**: ä¿®æ”¹`benchmark.py`ä¸­çš„`calculate_metrics`æ–¹æ³•ï¼Œè¿‡æ»¤ç‰¹å®šç±»åˆ«ã€‚

### Q4: é€Ÿåº¦æµ‹è¯•ä¸å‡†ç¡®

**A**: 
- ç¬¬ä¸€æ¬¡æ¨ç†ä¼šæ…¢ï¼ˆæ¨¡å‹åŠ è½½ã€CUDAåˆå§‹åŒ–ï¼‰
- è¿è¡Œå¤šæ¬¡å–å¹³å‡
- è€ƒè™‘warm-up run

### Q5: å¦‚ä½•è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Ÿ

**A**: å‡†å¤‡å¤šä¸ªæµ‹è¯•é›†ï¼š
- åŒåˆ†å¸ƒæµ‹è¯•é›†ï¼ˆä¸è®­ç»ƒé›†ç›¸åŒæ¥æºï¼‰
- è·¨åŸŸæµ‹è¯•é›†ï¼ˆä¸åŒPCBé¢œè‰²ã€ä¸åŒæ‹æ‘„æ¡ä»¶ï¼‰

### Q6: ç»“æœCSVå¦‚ä½•ç”¨äºå¯è§†åŒ–ï¼Ÿ

**A**: ä½¿ç”¨pandas/matplotlibï¼š

```python
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('benchmark_results/benchmark_20241103.csv')

# ç»˜åˆ¶å„ç±»åˆ«AP
df.groupby('class')['ap'].mean().plot(kind='bar')
plt.title('Per-Class Average Precision')
plt.ylabel('AP')
plt.show()
```

---

## è¿›é˜¶ä½¿ç”¨

### é›†æˆåˆ°CI/CD

```yaml
# .github/workflows/benchmark.yml
name: Weekly Benchmark
on:
  schedule:
    - cron: '0 0 * * 0'  # æ¯å‘¨æ—¥è¿è¡Œ

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run Benchmark
        run: |
          python benchmark.py --dataset_path test_data/
          python scripts/upload_results.py
```

### è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ

```python
# ç”ŸæˆMarkdownæŠ¥å‘Š
from benchmark import PCBBenchmark

benchmark = PCBBenchmark(...)
results = benchmark.run_benchmark()

with open('RESULTS.md', 'w') as f:
    f.write(f"# Benchmark Results\n\n")
    f.write(f"**Date**: {results['timestamp']}\n\n")
    f.write(f"**mAP**: {results['metrics']['overall']['mAP']:.4f}\n\n")
    # ... æ›´å¤šå†…å®¹
```

---

## è´¡çŒ®ä¸åé¦ˆ

å¦‚æœä½ æœ‰æ”¹è¿›å»ºè®®æˆ–å‘ç°bugï¼Œæ¬¢è¿æIssueæˆ–PRï¼

**å¸¸è§æ”¹è¿›æ–¹å‘**:
- [ ] æ”¯æŒCOCOæ ¼å¼æ ‡æ³¨
- [ ] å¢åŠ æ··æ·†çŸ©é˜µå¯è§†åŒ–
- [ ] PRæ›²çº¿ç»˜åˆ¶
- [ ] æ”¯æŒåˆ†å¸ƒå¼è¯„ä¼°ï¼ˆå¤šGPUï¼‰
- [ ] Webç•Œé¢å±•ç¤ºç»“æœ

---

## å‚è€ƒèµ„æ–™

- [YOLOç³»åˆ—è®ºæ–‡](https://github.com/ultralytics/ultralytics)
- [COCOè¯„ä¼°æŒ‡æ ‡](https://cocodataset.org/#detection-eval)
- [ç›®æ ‡æ£€æµ‹è¯„ä¼°æœ€ä½³å®è·µ](https://github.com/rafaelpadilla/Object-Detection-Metrics)

